# 参考资料

* 【未解决】搞懂IP代理池相关概念和逻辑
* 
* [crifanLib.cs之Http](https://www.crifan.com/files/doc/docbook/crifanlib_csharp/release/html/crifanlib_csharp.html#http)
* [HTTP知识总结](http://book.crifan.com/books/http_summary/website)
* [app抓包利器：Charles](http://book.crifan.com/books/app_capture_package_tool_charles/website)
* [JSON详解](https://www.crifan.com/files/doc/docbook/json_tutorial/release/html/json_tutorial.html)
* [主流数据格式：JSON](http://book.crifan.com/books/common_data_format_json/website)
* [【已解决】C#中解析Json字符串](https://www.crifan.com/csharp_parse_json_string/)
* [【记录】Python中尝试用lxml去解析html](https://www.crifan.com/python_try_lxml_parse_html/)
* [Python爬虫框架：PySpider](https://book.crifan.com/books/python_spider_pyspider/website/)
* [Scrapy](https://scrapy.org/)
* [Selenium知识总结](http://book.crifan.com/books/selenium_summary/website)
* [主流Python框架：Scrapy](http://book.crifan.com/books/python_spider_scrapy/website)
* [【记录】C#中的HTML解析 – 在路上](https://www.crifan.com/record_csharp_html_parser/)
* [如何用Python写爬虫](http://book.crifan.com/books/use_python_write_spider/website)
* [XPath知识总结](http://book.crifan.com/books/xpath_summary/website)
* [【整理】和PHP的HTTP,网页抓取,网络爬虫相关的库,框架,资料 – 在路上](https://www.crifan.com/summary_php_website_crawl_related_library_function/)
* [【教程】抓取网并提取网页中所需要的信息 之 C#版](http://www.crifan.com/crawl_website_html_and_extract_info_using_csharp)
* [【教程】模拟登陆网站 之 C#版（内含两种版本的完整的可运行的代码）](http://www.crifan.com/emulate_login_website_using_csharp/)
* [【教程】模拟登陆网站 之 Python版（内含两种版本的完整的可运行的代码）](http://www.crifan.com/emulate_login_website_using_python/)
* [【记录】用go语言实现模拟登陆百度](http://www.crifan.com/emulate_login_baidu_using_go_language/)
* [【教程】模拟登陆百度之Java代码版](http://www.crifan.com/emulate_login_baidu_use_java_code/)
* [Python心得：操作CSV和Excel](http://book.crifan.com/books/python_experience_csv_excel/website)
* [主流关系数据库：MySQL](http://book.crifan.com/books/popular_rmdb_mysql/website/)
* [主流文档型数据库：MongoDB](http://book.crifan.com/books/popular_document_db_mongodb/website)
* [Python中的正则表达式：re模块详解](http://book.crifan.com/books/python_regular_expression_re_intro/website)
* [【整理】Mac中用Charles抓包iOS或Android手机app中包括https的数据](http://www.crifan.com/mac_use_charles_capture_crawl_ios_android_phone_app_data_include_https_package)
* [【记录】模拟登陆google](https://www.crifan.com/files/doc/docbook/web_scrape_emulate_login/release/html/web_scrape_emulate_login.html)
* [【教程】如何抓取动态网页内容](http://www.crifan.com/how_to_crawl_dynamic_webpage_content)
* [【教程】以抓取网易博客帖子中的最近读者信息为例，手把手教你如何抓取动态网页中的内容](http://www.crifan.com/example_to_crawl_dynamic_webpage_content_of_recent_reader_info_for_netease_blog_post)
* [【经验总结】Http，网页访问，HttpRequest，HttpResponse相关的知识 – 在路上](https://www.crifan.com/http_web_technology_experience_summary/)
* [如何用Python，C#等语言去实现抓取静态网页+抓取动态网页+模拟登陆网站 – 在路上](https://www.crifan.com/how_to_use_some_language_python_csharp_to_implement_crawl_website_extract_dynamic_webpage_content_emulate_login_website/)
* [字符编码详解与应用](https://book.crifan.com/books/str_encoding_detail_application/website/)
* [安卓应用的安全和破解](https://book.crifan.com/books/android_app_security_crack/website/)
* 
* [Grab](https://grablab.org/docs/)
* [python-goose](https://github.com/grangier/python-goose)
* [PySpider](http://docs.pyspider.org/)
* [Portia](https://github.com/scrapinghub/portia)
* [newspaper](https://github.com/codelucas/newspaper)
* [ruia](https://github.com/howie6879/ruia)
* [Cola](https://github.com/chineking/cola)
* [Sasila](https://github.com/DarkSand/Sasila)
* [Nutch](http://lucene.apache.org/nutch/)
* [Heritrix](http://crawler.archive.org/)
* [crawler4j](https://github.com/yasserg/crawler4j)
* [WebMagic](https://webmagic.io/)
* [Colly](https://github.com/gocolly/colly)
* [Pholcus](https://github.com/henrylee2cn/pholcus)
* [headless-chrome-crawler](https://github.com/yujiosaka/headless-chrome-crawler)
* [scrapy中的提取正文的方法-python,爬虫,scrapy研究-51CTO博客](https://blog.51cto.com/pcliuyang/1543031)
* [基于Python的Scrapy爬虫入门：页面提取 SegmentFault](https://segmentfault.com/a/1190000012188139)
* [Scrapy定向爬虫教程(二)——提取网页内容 - 春华秋实 - CSDN博客](https://blog.csdn.net/qq_36330643/article/details/71547448)
* [Scrapy笔记04- Selector详解 | 飞污熊](https://www.xncoding.com/2016/03/14/scrapy-04.html)
* [Scrapy爬虫抓取网站数据 | ShinChan's Blog](https://chenqx.github.io/2014/11/09/Scrapy-Tutorial-for-BBSSpider/)
* [Scrapy爬虫入门教程十二 Link Extractors（链接提取器） - inke的博客 - CSDN博客](https://blog.csdn.net/Inke88/article/details/61204579)
* [基于WebMagic的CSDN博客爬虫 - zhuqiuhui的专栏 - CSDN博客](http://blog.csdn.net/zhuqiuhui/article/details/65449648)
* [Heritrix与Nutch对比 - 爱专集](http://www.aizhuanji.com/a/rw0naJlW.html)
* [Nutch、heritrix、crawler4j优缺点 - CSDN博客](http://blog.csdn.net/xiaomin1991222/article/details/50980580)
* [爬虫用哪个好？ - 知乎](https://www.zhihu.com/question/26476985)
* [作为基础服务的数据采集，发展到哪个阶段了？_搜狐科技_搜狐网](http://www.sohu.com/a/148146976_114778)
* [Python3网络爬虫(四)：使用User Agent和代理IP隐藏身份 - Jack-Cui - CSDN博客](https://blog.csdn.net/c406495762/article/details/60137956)
* [Python 爬虫一些常用的UA(user-agent) - abe_abd的博客 - CSDN博客](https://blog.csdn.net/abe_abd/article/details/73302236)
* [如何评价可以自动更换 User-Agent 的爬虫设计？ - 知乎](https://www.zhihu.com/question/34980963)
* [DarkSand/Sasila: 一个灵活、友好的爬虫框架](https://github.com/DarkSand/Sasila)
* [Python有哪些常见的、好用的爬虫框架？ - 知乎](https://www.zhihu.com/question/60280580)
* [8个最高效的Python爬虫框架，你用过几个？ - 个人文章 - SegmentFault 思否](https://segmentfault.com/a/1190000015131017)
* [爬虫的几种抓取策略 | 阿布云 - 因为专业·所以简单](https://www.abuyun.com/news/view-174.html)
* [【爬虫工程师招聘】智慧芽爬虫工程师招聘-BOSS直聘](https://www.zhipin.com/job_detail/1415652341.html)
* [【数据采集招聘】智慧芽数据采集招聘-BOSS直聘](https://www.zhipin.com/job_detail/1414952076.html)
* [【高级爬虫工程师招聘】智慧芽高级爬虫工程师招聘-BOSS直聘](https://www.zhipin.com/job_detail/1415603337.html)
* [如何对知乎内容进行爬虫？ - 知乎](https://www.zhihu.com/question/27850529)
* [用爬虫在各大机场自动签到获取流量](https://lemea.co/index.php/archives/17/)
* [每天理财网站登陆签到获取积分](https://www.jianshu.com/p/bfa23227f089)
* [浦发信用卡自动签到](https://blog.dianqk.org/2019/02/20/entry-voice-union/)
* [自制BILIBILI弹幕爬取，签到，抢楼等爬虫](https://github.com/qq519043202/BILI)
* [Selenium](https://www.seleniumhq.org)
* [梦见蜘蛛网_国学易经](http://www.zhouyi110.com/meng/wupin/13552.html)
* [Python爬虫原理 - Python开发之路 - 博客园](https://www.cnblogs.com/sss4/p/7809821.html)
* [蜻蜓代理 - 企业级高质量代理ip平台](https://proxy.horocn.com)
* [讯代理-爬虫代理-HTTP代理-代理服务器](http://www.xdaili.cn)
* [BruceDone/awesome-crawler: A collection of awesome web crawler,spider in different languages](https://github.com/BruceDone/awesome-crawler)
* 